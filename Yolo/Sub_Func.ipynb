{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1f3a6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: type object 'IOLoop' has no attribute 'initialized'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ast import In\n",
    "from posixpath import split\n",
    "from pyexpat import model\n",
    "from zlib import DEF_MEM_LEVEL\n",
    "import caffe.proto.caffe_pb2 as caffe_pb2\n",
    "import google.protobuf as pb\n",
    "import google.protobuf.text_format\n",
    "from caffe import layers as L\n",
    "import caffe\n",
    "import os\n",
    "import keras\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Layers={}\n",
    "Main_Layers['bvlc_alexnet.caffemodel']=['data','conv1','conv2','conv3','conv4','conv5','fc6','fc7','fc8']\n",
    "Main_Layers['bvlc_googlenet.caffemodel']=['data','conv1/7x7_s2','conv2/3x3_reduce','conv2/3x3',\n",
    "    'inception_3a/1x1','inception_3b/1x1','inception_4a/1x1','inception_4b/1x1','inception_4c/1x1',\n",
    "    'inception_4d/1x1','inception_4e/1x1','inception_5a/1x1','inception_5b/1x1','loss3/classifier']\n",
    "Main_Layers['squeezenet_v1.0.caffemodel']=['data','conv1','fire2/squeeze1x1','fire2/expand1x1',\n",
    "    'fire3/squeeze1x1','fire3/expand1x1','fire4/squeeze1x1','fire4/expand1x1','fire5/squeeze1x1',\n",
    "    'fire5/expand1x1','fire6/squeeze1x1','fire6/expand1x1','fire7/squeeze1x1','fire7/expand1x1',\n",
    "    'fire8/squeeze1x1','fire8/expand1x1','fire9/squeeze1x1','fire9/expand1x1','conv10','prob']\n",
    "Main_Layers['MobileNet.h5']=['input_2','conv1_pad','conv_dw_1','conv_pw_1','conv_pad_2','conv_pw_2',\n",
    "    'conv_dw_3','conv_pw_3','conv_pad_4','conv_pw_4','conv_dw_5','conv_pw_5','conv_pad_6','conv_pw_6',\n",
    "    'conv_dw_7','conv_pw_7','conv_dw_8','conv_pw_8','conv_dw_9','conv_pw_9','conv_dw_10','conv_pw_10',\n",
    "    'conv_dw_11','conv_pw_11','conv_pad_12','conv_pw_12','conv_dw_13','conv_pw_13','conv_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca0ce3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Main_Layers['ResNet50.h5']=['input_1','conv1_pad','res2a_branch2a','res2b_branch2a','res2c_branch2a',\n",
    "    'res3a_branch2a','res3b_branch2a','res3c_branch2a','res3d_branch2a','res4a_branch2a','res4b_branch2a',\n",
    "    'res4c_branch2a','res4d_branch2a','res4e_branch2a','res4f_branch2a','res5a_branch2a','res5b_branch2a',\n",
    "    'res5c_branch2a','fc1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_dir=\"/home/ehsan/UvA/ARMCL/Khadas/ARMCL-Local/scripts/blobs_extractor/Working_tree/Sub_Model/\"\n",
    "_dir=\"/home/ehsan/UvA/Sub_Model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e863539d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d638b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def Load_Net(M='bvlc_alexnet.caffemodel',Structure='deploy.prototxt'):\n",
    "    global net \n",
    "    net = caffe_pb2.NetParameter()\n",
    "    global Model  \n",
    "    Model = caffe.Net(Structure, 1, weights=M)\n",
    "    with open(Structure, 'r') as f:\n",
    "        pb.text_format.Merge(f.read(), net)\n",
    "    global main_layers\n",
    "    main_layers=Main_Layers[M.split('/')[-1]]\n",
    "    print(f'Model {M} loaded.')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Net_Keras(Model_name):\n",
    "    global model\n",
    "    model=keras.models.load_model(Model_name)\n",
    "    global main_layers\n",
    "    main_layers=Main_Layers[Model_name.split('/')[-1]]\n",
    "    print(f'Model {Model_name} loaded.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_Net(Name):\n",
    "    #Name=Name+'.prototxt'\n",
    "    with open(Name, 'w') as f:\n",
    "        f.write(pb.text_format.MessageToString(net))\n",
    "\n",
    "    print(f'Model saved as {Name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ac680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fill_Indexes():\n",
    "    global dict\n",
    "    dict={}\n",
    "    layers=net.layer\n",
    "    print(len(layers))\n",
    "    layer=0\n",
    "    started=0\n",
    "    for i in range(len(layers)):\n",
    "        if layers[i].name in main_layers:\n",
    "            if started:\n",
    "                dict[layer].setdefault('end',i-1)\n",
    "                print(layer,dict[layer]['name'],dict[layer]['start'],dict[layer]['end'])\n",
    "                layer=layer+1\n",
    "                dict.setdefault(layer,{})\n",
    "                dict[layer].setdefault('name',main_layers[layer])\n",
    "                dict[layer].setdefault('start',i)\n",
    "            else:                               \n",
    "                dict.setdefault(layer,{})\n",
    "                dict[layer].setdefault('name',main_layers[layer])\n",
    "                dict[layer].setdefault('start',i)\n",
    "                started=1\n",
    "        if i==(len(layers)-1):\n",
    "            dict[layer].setdefault('end',i)\n",
    "            print(layer,dict[layer]['name'],dict[layer]['start'],dict[layer]['end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6d1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbde43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fill_Indexes_keras(model_name):\n",
    "    global dict\n",
    "    dict={}\n",
    "    #net=keras.models.load_model(model_name)\n",
    "    layers=model.layers\n",
    "    print(len(layers))\n",
    "    layer=0\n",
    "    started=0\n",
    "    for i in range(len(layers)):\n",
    "        #print(layers[i].name)\n",
    "        \n",
    "        if layers[i].name in main_layers:\n",
    "            if started:\n",
    "                dict[layer].setdefault('end',i-1)\n",
    "                print(layer,dict[layer]['name'],dict[layer]['start'],dict[layer]['end'])\n",
    "                layer=layer+1\n",
    "                dict.setdefault(layer,{})\n",
    "                dict[layer].setdefault('name',main_layers[layer])\n",
    "                dict[layer].setdefault('start',i)\n",
    "                print(f'\\n\\n\\nlayer {main_layers[layer]}, input :{layers[i].input.shape}')\n",
    "            else:                               \n",
    "                dict.setdefault(layer,{})\n",
    "                dict[layer].setdefault('name',main_layers[layer])\n",
    "                dict[layer].setdefault('start',i)\n",
    "                started=1\n",
    "                print(f'\\n\\n\\nlayer {main_layers[layer]}, input :{layers[i].name},{layers[i].input.shape}')\n",
    "        if i==(len(layers)-1):\n",
    "            dict[layer].setdefault('end',i)\n",
    "            print(layer,dict[layer]['name'],dict[layer]['start'],dict[layer]['end'])\n",
    "\n",
    "        print(f'sublayer {layers[i].name}, output shape :{layers[i].output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d034fd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05bdc39",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def Slice(Start,End):\n",
    "    # Extract Input shape of start layer\n",
    "    \n",
    "    Bottom_Name=Model.bottom_names[main_layers[Start]][0]\n",
    "    print(f'Previous layer name:{Bottom_Name}')\n",
    "    Input_Shape=Model.blobs[Bottom_Name].data.shape\n",
    "    if len(Input_Shape) == 2:\n",
    "    \tInput_Shape=Input_Shape[:1]+(1,1,)+Input_Shape[1:]\n",
    "    print(f'Input shape is:{Input_Shape}')\n",
    "    #for b in Model.blobs:\n",
    "    #\tprint(Model.blobs[b].data.shape)\n",
    "\n",
    "    # Set input shape to Extracted Shape\n",
    "    input=net.layer[0]\n",
    "    shape=input.input_param.shape[0]\n",
    "    shape.Clear()\n",
    "    shape.dim.MergeFrom(Input_Shape)\n",
    "\n",
    "    # Slice the model using indexed dict\n",
    "    Start_index=dict[Start]['start']\n",
    "    End_index=dict[End]['end']\n",
    "    print(f'Start and end indexes are: {Start_index,End_index}')\n",
    "    del net.layer[End_index+1:]\n",
    "    \n",
    "    previous_layer_name=net.layer[Start_index-1].name\n",
    "    previous_layer_name2=main_layers[Start-1]\n",
    "    del net.layer[1:Start_index]\n",
    "\n",
    "    '''\n",
    "    # Connect start layer to input layer \n",
    "    C1=net.layer[1]\n",
    "    C1.ClearField('bottom')\n",
    "    C1.bottom.append(input.name)\n",
    "    '''\n",
    "\n",
    "    # Connect start layers to input layer (Considering multiple parallel input layer)\n",
    "    print(f'Name of previousl layer {previous_layer_name} and {previous_layer_name2} and also {Bottom_Name}')\n",
    "    for l in net.layer:\n",
    "        print(f'bottom of {l.name}:{l.bottom}')\n",
    "        if l.bottom==[previous_layer_name] or l.bottom==[previous_layer_name2] or l.bottom==[Bottom_Name]:\n",
    "            print(f'new first layer after data:{l}')\n",
    "            l.ClearField('bottom')\n",
    "            l.bottom.append(input.name)\n",
    "    #print(net.layer)\n",
    "    \n",
    "    print(f'Model sliced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_keras(model_name,Start,End):\n",
    "    \n",
    "\n",
    "    Start_index=dict[Start]['start']\n",
    "    End_index=dict[End]['end']\n",
    "\n",
    "    #model=keras.models.load_model(model_name)\n",
    "    #DL_input = keras.layers.Input(model.layers[indx].input_shape[1:])\n",
    "    print(f'Input shape is:{model.layers[Start_index].get_input_shape_at(0)[1:]}')\n",
    "    print(f'Start and end indexes are: {Start_index,End_index}')\n",
    "    \n",
    "    p_layer=model.layers[Start_index-1]\n",
    "    DL_input = keras.layers.Input(model.layers[Start_index].get_input_shape_at(0)[1:],name='my_input')\n",
    "    DL_model = DL_input\n",
    "    DL_model = model.layers[Start_index](DL_model)\n",
    "    #ll=model.layers[:]\n",
    "    for layer in model.layers[Start_index+1:End_index+1]:\n",
    "        layer_in_shape=0\n",
    "        if isinstance(layer.input, list):\n",
    "            layer_in_shape=layer.input[0].shape\n",
    "        else:\n",
    "            layer_in_shape=layer.input.shape\n",
    "        DL_model_name=0\n",
    "        DL_model_shape=0\n",
    "        if isinstance(DL_model,list):\n",
    "            DL_model_shape=DL_model[0].shape\n",
    "            DL_model_name=DL_model[0].name\n",
    "        else:\n",
    "            DL_model_shape=DL_model.shape\n",
    "            DL_model_name=DL_model.name\n",
    "        print(f'adding layer: {layer.name} with shape {layer_in_shape} to {DL_model_name} with shape {DL_model_shape}')\n",
    "        if type(layer.input)==type([]): \n",
    "            if p_layer.output in layer.input:\n",
    "                DL_model = layer([DL_input,DL_model])\n",
    "            else:\n",
    "                for l in model.layers:\n",
    "                    if l.output in layer.input:\n",
    "                        DL_model = layer([l.get_output_at(1),DL_model])\n",
    "                        break\n",
    "        else:\n",
    "            DL_model = layer(DL_model)\n",
    "        \n",
    "    DL_model = keras.models.Model(inputs=DL_input, outputs=DL_model)\n",
    "    \n",
    "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    print(f'Model sliced')\n",
    "    _dir=os.path.dirname(model_name)\n",
    "    _ext=os.path.splitext(model_name)[1]\n",
    "    new_name=_dir+'/'+model_name.split('/')[-2]+'_'+str(Start)+'_'+str(End)+_ext\n",
    "    pb_name=_dir+'/'+model_name.split('/')[-2]+'_'+str(Start)+'_'+str(End)+'.pb'\n",
    "    DL_model.save(new_name)\n",
    "    #DL_model.summary()\n",
    "    print(f'Model saved as {new_name}')\n",
    "    #print(f'Model input:{DL_model.input.name}, Output:{DL_model.output.name}, input_shape:{DL_model.input.shape}')\n",
    "    global pb_convert_args\n",
    "    pb_convert_args={}\n",
    "    pb_convert_args['h5name']=new_name\n",
    "    pb_convert_args['pb_name']=pb_name\n",
    "    pb_convert_args['input']=DL_model.layers[0].name\n",
    "    pb_convert_args['output']=DL_model.layers[-1].get_output_at(0).op.name\n",
    "    shape=''\n",
    "    s=list(DL_model.layers[0].get_input_shape_at(0)[1:])\n",
    "    for x in s:\n",
    "        shape=shape+str(x)+','\n",
    "    shape=shape[:-1]\n",
    "    pb_convert_args['input_shape']=shape\n",
    "    for l in DL_model.layers:\n",
    "        print(f'name:{l.name} output:{l.get_output_at(0).name}')\n",
    "\n",
    "    return DL_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_keras_2(model_name,Start,End):\n",
    "    Start_index=dict[Start]['start']\n",
    "    End_index=dict[End]['end']\n",
    "\n",
    "    #model=keras.models.load_model(model_name)\n",
    "    \n",
    "    Input_shape=model.layers[Start_index].get_input_shape_at(0)[1:]\n",
    "    print(f'Input shape is:{Input_shape}')\n",
    "    print(f'Start and end indexes are: {Start_index,End_index}')\n",
    "    p_layer=model.layers[Start_index-1]\n",
    "    nodes=p_layer._outbound_nodes\n",
    "    Input_layer=keras.layers.InputLayer(input_shape=Input_shape,name=\"New_input\")\n",
    "    for node in nodes:\n",
    "        if p_layer.output in node.input_tensors:\n",
    "            node.input_tensors.remove(p_layer.output)\n",
    "        node.input_tensors.append(Input_layer.output)\n",
    "\n",
    "        if p_layer in node.inbound_layers:\n",
    "            node.inbound_layers.remove(p_layer)\n",
    "        node.inbound_layers.append(Input_layer)\n",
    "    Input_layer._outbound_nodes=nodes\n",
    "    if 'dropout' in model.layers[End_index].name:\n",
    "        print(f'The last layer is dropout, it should be deleted because error in converting to rknn (dropout should be in training no inference!)')\n",
    "        End_index=End_index-1\n",
    "    new_model=keras.models.Model(inputs=Input_layer.input,outputs=model.layers[End_index].output)\n",
    "    '''if 'dropout' in new_model.layers[-1].name:\n",
    "        print(f'The last layer is dropout, it should be deleted because error in converting to rknn (dropout should be in training no inference!)')\n",
    "        new_model.layers.pop()'''\n",
    "        \n",
    "    print(f'\\n\\nNew model First Layer:{new_model.layers[1].name}, Input shape:{new_model.layers[0].input.shape}\\n\\\n",
    "            Input name:{new_model.layers[0].name} First layer input shape:{new_model.layers[1].input.shape},\\n\\\n",
    "            Last layer name:{new_model.layers[-1].name} and {new_model.layers[-1].get_output_at(0).op.name}\\n\\\n",
    "            output shape:{new_model.layers[-1].output.shape}')\n",
    "\n",
    "    plot_model(new_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    print(f'Model sliced')\n",
    "    _dir=os.path.dirname(model_name)\n",
    "    _ext=os.path.splitext(model_name)[1]\n",
    "    new_name=_dir+'/'+model_name.split('/')[-2]+'_'+str(Start)+'_'+str(End)+_ext\n",
    "    pb_name=_dir+'/'+model_name.split('/')[-2]+'_'+str(Start)+'_'+str(End)+'.pb'\n",
    "    new_model.save(new_name)\n",
    "    #DL_model.summary()\n",
    "    print(f'Model saved as {new_name}')\n",
    "    #print(f'Model input:{DL_model.input.name}, Output:{DL_model.output.name}, input_shape:{DL_model.input.shape}')\n",
    "    global pb_convert_args\n",
    "    pb_convert_args={}\n",
    "    pb_convert_args['h5name']=new_name\n",
    "    pb_convert_args['pb_name']=pb_name\n",
    "    pb_convert_args['input']=new_model.layers[0].name\n",
    "    pb_convert_args['output']=new_model.layers[-1].get_output_at(0).op.name\n",
    "    shape=''\n",
    "    s=list(new_model.layers[0].get_input_shape_at(0)[1:])\n",
    "    for x in s:\n",
    "        shape=shape+str(x)+','\n",
    "    shape=shape[:-1]\n",
    "    pb_convert_args['input_shape']=shape\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ed3ea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main(Start,End, M, Structure):\n",
    "    Load_Net(M,Structure)\n",
    "    Fill_Indexes()\n",
    "    Slice(Start,End)\n",
    "\n",
    "    \n",
    "    _dir=os.path.dirname(Structure)\n",
    "    _ext=os.path.splitext(Structure)[1]\n",
    "    global Name\n",
    "    Name=_dir+'/'+Structure.split('/')[-2]+'_'+str(Start)+'_'+str(End)+_ext\n",
    "    Save_Net(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ac180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_keras(M,Start,End):\n",
    "    Load_Net_Keras(M)\n",
    "    Fill_Indexes_keras(M)\n",
    "    #print(dict)\n",
    "    split_keras_2(M,Start,End)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920de824",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Slice a model')\n",
    "    parser.add_argument('--Model', metavar='path', required=False,\n",
    "                        help='Model')\n",
    "    parser.add_argument('--Structure', metavar='path', required=False,\n",
    "                        help='Structure of the model (prototxt)')\n",
    "    parser.add_argument('--Start', metavar='number', required=True,\n",
    "                        help='Starting layer')\n",
    "    parser.add_argument('--End', metavar='number', required=True,\n",
    "                        help='Ending layer')\n",
    "\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    print(f'st is {args.Structure}')\n",
    "    if args.Model.split('.')[-1]=='h5':\n",
    "        main_keras(args.Model,int(args.Start),int(args.End))\n",
    "        if pb:\n",
    "            cmd1=f'python {_dir}keras_to_tensorflow.py --input_model={pb_convert_args[\"h5name\"]} --output_model={pb_convert_args[\"pb_name\"]}'\n",
    "            print(f'command is: {cmd1}')\n",
    "            ok=os.system(cmd1)\n",
    "            print(f'Freezing graph return code is {ok} ')\n",
    "            cmd2=f'python {_dir}convert.py {pb_convert_args[\"pb_name\"]} {pb_convert_args[\"input\"]} {pb_convert_args[\"output\"]} {pb_convert_args[\"input_shape\"]}'\n",
    "            print(f'command is: {cmd2}')\n",
    "            ok=os.system(cmd2)\n",
    "            print(f'Convert to rknn return code is {ok} ')\n",
    "    else:\n",
    "        main(Start=int(args.Start), End=int(args.End), M=args.Model, Structure=args.Structure)\n",
    "        cmd=f'python {_dir}convert.py {Name} {args.Model}'\n",
    "        print(f'command is {cmd}')\n",
    "        ok=os.system(cmd)\n",
    "        print(f'Convert caffe to rknn return code is {ok}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e03f7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d9b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Temp():\n",
    "    input=net.layer[0];\n",
    "    shape=kk=input.input_param.shape[0];\n",
    "    shape.Clear();\n",
    "    shape.dim.MergeFrom([10,256,13,13]);\n",
    "\n",
    "    del net.layer[1:9]\n",
    "    del net.layer[5:]\n",
    "    C1=net.layer[1]\n",
    "    C1.ClearField('bottom')\n",
    "    C1.bottom.append(input.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bef06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "rock-kit3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd2c8e99263702e5d843854558acee7b813700db9b74d62479eb5653a7f03adf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
